{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pBQsZEJmubLs"
   },
   "source": [
    "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
    "<br></br>\n",
    "\n",
    "# Neural Network Framework (Keras)\n",
    "\n",
    "## *Data Science Unit 4 Sprint 2 Assignment 3*\n",
    "\n",
    "## Use the Keras Library to build a Multi-Layer Perceptron Model on the Boston Housing dataset\n",
    "\n",
    "- The Boston Housing dataset comes with the Keras library so use Keras to import it into your notebook. \n",
    "- Normalize the data (all features should have roughly the same scale)\n",
    "- Import the type of model and layers that you will need from Keras.\n",
    "- Instantiate a model object and use `model.add()` to add layers to your model\n",
    "- Since this is a regression model you will have a single output node in the final layer.\n",
    "- Use activation functions that are appropriate for this task\n",
    "- Compile your model\n",
    "- Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "- Do a little bit of feature engineering and see how that affects your neural network model. (you will need to change your model to accept more inputs)\n",
    "- After feature engineering, which model sees a greater accuracy boost due to the new features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8NLTAR87uYJ-"
   },
   "outputs": [],
   "source": [
    "##### Your Code Here #####\n",
    "\n",
    "from tensorflow.keras.datasets import boston_housing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Data\n",
    "(X_train, y_train), (X_test, y_test) = boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape:  (404, 13)\n",
      "y_train shape:  (404,)\n"
     ]
    }
   ],
   "source": [
    "print(\"X_train shape: \", X_train.shape)\n",
    "print(\"y_train shape: \", y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.1770e-02, 8.2500e+01, 2.0300e+00, 0.0000e+00, 4.1500e-01,\n",
       "       7.6100e+00, 1.5700e+01, 6.2700e+00, 2.0000e+00, 3.4800e+02,\n",
       "       1.4700e+01, 3.9538e+02, 3.1100e+00])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42.3"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Normalize the data (all features should have roughly the same scale)\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "X_train_minmax = scaler.fit_transform(X_train)\n",
    "X_test_minmax = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(404, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1.37816304e-02, 0.00000000e+00, 2.81524927e-01, 0.00000000e+00,\n",
       "        3.14814815e-01, 4.99806352e-01, 9.14521112e-01, 2.97191228e-01,\n",
       "        1.30434783e-01, 2.27533461e-01, 8.93617021e-01, 1.00000000e+00,\n",
       "        4.68818985e-01],\n",
       "       [1.73654275e-04, 8.25000000e-01, 5.75513196e-02, 0.00000000e+00,\n",
       "        6.17283951e-02, 7.84082107e-01, 1.31822863e-01, 5.36536996e-01,\n",
       "        4.34782609e-02, 3.05927342e-01, 2.23404255e-01, 9.96167230e-01,\n",
       "        3.80794702e-02]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_train_minmax.shape)\n",
    "X_train_minmax[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(102, 13)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.20319551, 0.        , 0.64662757, 0.        , 0.60493827,\n",
       "        0.55635167, 1.        , 0.07359588, 1.        , 0.91395793,\n",
       "        0.80851064, 0.06790559, 0.75386313],\n",
       "       [0.00131471, 0.        , 0.35007331, 0.        , 0.33333333,\n",
       "        0.45546088, 0.92687951, 0.12773597, 0.2173913 , 0.4665392 ,\n",
       "        0.55319149, 0.99508296, 0.3995585 ]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_test_minmax.shape)\n",
    "X_test_minmax[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the type of model and layers that you will need from Keras\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "\n",
    "np.random.seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantiate a model object and use model.add() to add layers to your model\n",
    "#Since this is a regression model you will have a single output node in the final layer.\n",
    "#Use activation functions that are appropriate for this task\n",
    "#define Model\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim = 13, activation = 'relu'))\n",
    "model.add(Dense(64, activation = 'relu'))\n",
    "model.add(Dense(1, activation = 'linear'))\n",
    "\n",
    "#compile the model\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "13/13 [==============================] - 0s 10ms/step - loss: 574.7212 - accuracy: 0.0000e+00 - val_loss: 2931.6765 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 545.7730 - accuracy: 0.0000e+00 - val_loss: 30761.1738 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 499.2091 - accuracy: 0.0000e+00 - val_loss: 135889.2656 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 422.3084 - accuracy: 0.0000e+00 - val_loss: 503225.1875 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 312.8817 - accuracy: 0.0000e+00 - val_loss: 1547848.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 202.2928 - accuracy: 0.0000e+00 - val_loss: 3756877.7500 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 138.7953 - accuracy: 0.0000e+00 - val_loss: 6104110.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 123.7859 - accuracy: 0.0000e+00 - val_loss: 6506614.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 110.2432 - accuracy: 0.0000e+00 - val_loss: 5882048.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 98.4963 - accuracy: 0.0000e+00 - val_loss: 5522617.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 88.5072 - accuracy: 0.0000e+00 - val_loss: 5759105.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 79.1376 - accuracy: 0.0000e+00 - val_loss: 5820327.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 71.9990 - accuracy: 0.0000e+00 - val_loss: 5690454.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 65.5530 - accuracy: 0.0000e+00 - val_loss: 5681335.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 60.5410 - accuracy: 0.0000e+00 - val_loss: 5652502.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 56.9936 - accuracy: 0.0000e+00 - val_loss: 5817321.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 53.8760 - accuracy: 0.0000e+00 - val_loss: 5486914.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 51.1992 - accuracy: 0.0000e+00 - val_loss: 5693130.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 49.3807 - accuracy: 0.0000e+00 - val_loss: 5790789.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 48.1028 - accuracy: 0.0000e+00 - val_loss: 5795751.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/100\n",
      "13/13 [==============================] - 0s 3ms/step - loss: 46.4116 - accuracy: 0.0000e+00 - val_loss: 5598112.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 44.8409 - accuracy: 0.0000e+00 - val_loss: 5867719.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 43.6096 - accuracy: 0.0000e+00 - val_loss: 5894621.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/100\n",
      "13/13 [==============================] - 0s 30ms/step - loss: 42.3463 - accuracy: 0.0000e+00 - val_loss: 5932425.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 41.2085 - accuracy: 0.0000e+00 - val_loss: 5974434.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 40.2724 - accuracy: 0.0000e+00 - val_loss: 6006644.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 39.1999 - accuracy: 0.0000e+00 - val_loss: 6352174.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 37.6792 - accuracy: 0.0000e+00 - val_loss: 6131786.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 36.6830 - accuracy: 0.0000e+00 - val_loss: 6366032.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 35.4532 - accuracy: 0.0000e+00 - val_loss: 6477643.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 34.5612 - accuracy: 0.0000e+00 - val_loss: 6488500.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 33.5193 - accuracy: 0.0000e+00 - val_loss: 6862818.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 32.4636 - accuracy: 0.0000e+00 - val_loss: 6759347.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 31.4274 - accuracy: 0.0000e+00 - val_loss: 6801321.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 30.7476 - accuracy: 0.0000e+00 - val_loss: 7012438.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 29.5370 - accuracy: 0.0000e+00 - val_loss: 7081915.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 28.6354 - accuracy: 0.0000e+00 - val_loss: 7212412.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.8603 - accuracy: 0.0000e+00 - val_loss: 7417157.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 27.0100 - accuracy: 0.0000e+00 - val_loss: 7626513.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 26.1318 - accuracy: 0.0000e+00 - val_loss: 7764512.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 25.4074 - accuracy: 0.0000e+00 - val_loss: 7915668.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 24.7594 - accuracy: 0.0000e+00 - val_loss: 8210402.5000 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 24.0708 - accuracy: 0.0000e+00 - val_loss: 8142089.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.5519 - accuracy: 0.0000e+00 - val_loss: 8358671.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 23.1551 - accuracy: 0.0000e+00 - val_loss: 8510055.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.6196 - accuracy: 0.0000e+00 - val_loss: 8514251.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 22.1517 - accuracy: 0.0000e+00 - val_loss: 8724423.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.8750 - accuracy: 0.0000e+00 - val_loss: 8875694.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.8394 - accuracy: 0.0000e+00 - val_loss: 8926369.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 21.1987 - accuracy: 0.0000e+00 - val_loss: 8839906.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.9867 - accuracy: 0.0000e+00 - val_loss: 9191334.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 20.7560 - accuracy: 0.0000e+00 - val_loss: 9000472.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.4654 - accuracy: 0.0000e+00 - val_loss: 9173638.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.4400 - accuracy: 0.0000e+00 - val_loss: 9339652.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 20.1080 - accuracy: 0.0000e+00 - val_loss: 9216339.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7636 - accuracy: 0.0000e+00 - val_loss: 9498283.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7717 - accuracy: 0.0000e+00 - val_loss: 9363534.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4341 - accuracy: 0.0000e+00 - val_loss: 9545388.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.4727 - accuracy: 0.0000e+00 - val_loss: 9586919.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.3173 - accuracy: 0.0000e+00 - val_loss: 9854032.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.8637 - accuracy: 0.0000e+00 - val_loss: 9778731.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.7373 - accuracy: 0.0000e+00 - val_loss: 9881347.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 19.0375 - accuracy: 0.0000e+00 - val_loss: 9825502.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.3277 - accuracy: 0.0000e+00 - val_loss: 10203622.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.3311 - accuracy: 0.0000e+00 - val_loss: 10252047.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 18.0965 - accuracy: 0.0000e+00 - val_loss: 10209707.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.9007 - accuracy: 0.0000e+00 - val_loss: 10475080.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.7729 - accuracy: 0.0000e+00 - val_loss: 10544547.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.6620 - accuracy: 0.0000e+00 - val_loss: 10734532.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.7151 - accuracy: 0.0000e+00 - val_loss: 10798912.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.5058 - accuracy: 0.0000e+00 - val_loss: 10951227.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.4279 - accuracy: 0.0000e+00 - val_loss: 10816572.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.2034 - accuracy: 0.0000e+00 - val_loss: 11201151.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 17.4048 - accuracy: 0.0000e+00 - val_loss: 11203047.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.8941 - accuracy: 0.0000e+00 - val_loss: 11361476.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.7054 - accuracy: 0.0000e+00 - val_loss: 11364987.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.6651 - accuracy: 0.0000e+00 - val_loss: 11428938.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.8097 - accuracy: 0.0000e+00 - val_loss: 11532420.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.3720 - accuracy: 0.0000e+00 - val_loss: 11550062.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.4182 - accuracy: 0.0000e+00 - val_loss: 11596712.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.0640 - accuracy: 0.0000e+00 - val_loss: 11734202.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 16.1470 - accuracy: 0.0000e+00 - val_loss: 11960819.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 16.1749 - accuracy: 0.0000e+00 - val_loss: 12152476.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.7420 - accuracy: 0.0000e+00 - val_loss: 12245838.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 15.5372 - accuracy: 0.0000e+00 - val_loss: 12210446.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.5315 - accuracy: 0.0000e+00 - val_loss: 12435709.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.4071 - accuracy: 0.0000e+00 - val_loss: 12194753.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 14.9947 - accuracy: 0.0000e+00 - val_loss: 12646458.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.1945 - accuracy: 0.0000e+00 - val_loss: 12356146.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 15.1065 - accuracy: 0.0000e+00 - val_loss: 12855309.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.7493 - accuracy: 0.0000e+00 - val_loss: 12550041.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.8625 - accuracy: 0.0000e+00 - val_loss: 13052041.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.6861 - accuracy: 0.0000e+00 - val_loss: 13217057.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.4039 - accuracy: 0.0000e+00 - val_loss: 13194143.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.4083 - accuracy: 0.0000e+00 - val_loss: 13379160.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.3113 - accuracy: 0.0000e+00 - val_loss: 13146368.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.0774 - accuracy: 0.0000e+00 - val_loss: 13392732.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 14.0523 - accuracy: 0.0000e+00 - val_loss: 13909410.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/100\n",
      "13/13 [==============================] - 0s 5ms/step - loss: 13.7135 - accuracy: 0.0000e+00 - val_loss: 13604293.0000 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/100\n",
      "13/13 [==============================] - 0s 4ms/step - loss: 13.7182 - accuracy: 0.0000e+00 - val_loss: 13649983.0000 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "#Fit your model and report its accuracy in terms of Mean Squared Error\n",
    "hist = model.fit(X_train_minmax, y_train, epochs=100, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_20 (Dense)             (None, 64)                896       \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 5,121\n",
      "Trainable params: 5,121\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 13.4705 - accuracy: 0.0000e+00\n",
      "accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "# evaluate the model\n",
    "scores = model.evaluate(X_train_minmax, y_train)\n",
    "print(f\"{model.metrics_names[1]}: {scores[1]*100}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "# summarize history for loss\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(hist.history['loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train error: 22.004800838348142\n"
     ]
    }
   ],
   "source": [
    "#Run this same data through a linear regression model. Which achieves higher accuracy?\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "model = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_train)\n",
    "mse = mean_squared_error(y_train, y_pred)\n",
    "print(\"Train error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test error: 23.19559925642308\n"
     ]
    }
   ],
   "source": [
    "# Apply the model to test data\n",
    "#the keras gave better results. \n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"Test error:\", mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Do a little bit of feature engineering and see how that affects your neural network model. \n",
    "#(you will need to change your model to accept more inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature description: https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
    "1. CRIM - per capita crime rate by town\n",
    "2. ZN - proportion of residential land zoned for lots over 25,000 sq.ft.\n",
    "3. INDUS - proportion of non-retail business acres per town.\n",
    "4. CHAS - Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n",
    "5. NOX - nitric oxides concentration (parts per 10 million)\n",
    "6. RM - average number of rooms per dwelling\n",
    "7. AGE - proportion of owner-occupied units built prior to 1940\n",
    "8. DIS - weighted distances to five Boston employment centres\n",
    "9. RAD - index of accessibility to radial highways\n",
    "10. TAX - full-value property-tax rate per $10,000\n",
    "11. PTRATIO - pupil-teacher ratio by town\n",
    "12. B - 1000(Bk - 0.63)^2 where Bk is the proportion of blacks by town\n",
    "13. LSTAT - % lower status of the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SfcFnOONyuNm"
   },
   "source": [
    "## Use the Keras Library to build an image recognition network using the Fashion-MNIST dataset (also comes with keras)\n",
    "\n",
    "- Load and preprocess the image data similar to how we preprocessed the MNIST data in class.\n",
    "- Make sure to one-hot encode your category labels\n",
    "- The number of nodes in your output layer should equal the number of classes you want to predict for Fashion-MNIST.\n",
    "- Try different hyperparameters. What is the highest accuracy that you are able to achieve.\n",
    "- Use the history object that is returned from model.fit to make graphs of the model's loss or train/validation accuracies by epoch. \n",
    "- Remember that neural networks fall prey to randomness so you may need to run your model multiple times (or use Cross Validation) in order to tell if a change to a hyperparameter is truly producing better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "szi6-IpuzaH1"
   },
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "import numpy as np\n",
    "np.random.seed(812)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load de data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X Variable Types\n",
    "num_classes = 10\n",
    "\n",
    "X_train = X_train.astype('float32') / 255.\n",
    "X_test = X_test.astype('float32') / 255.\n",
    "\n",
    "# Correct Encoding on Y\n",
    "# What softmax expects = [0,0,0,0,0,1,0,0,0,0]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "\n",
    "import os\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "\n",
    "logdir = os.path.join(\"logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2616 - accuracy: 0.9245 - val_loss: 0.1354 - val_accuracy: 0.9603\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1146 - accuracy: 0.9660 - val_loss: 0.0993 - val_accuracy: 0.9694\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0797 - accuracy: 0.9766 - val_loss: 0.0784 - val_accuracy: 0.9746\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0586 - accuracy: 0.9823 - val_loss: 0.0678 - val_accuracy: 0.9789\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0455 - accuracy: 0.9859 - val_loss: 0.0704 - val_accuracy: 0.9780\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14a84b7f0>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Flatten\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=X_train, \n",
    "        y=y_train, \n",
    "        epochs=5, \n",
    "        validation_data=(X_test, y_test), \n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.2551 - accuracy: 0.9279 - val_loss: 0.1358 - val_accuracy: 0.9592\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.1130 - accuracy: 0.9664 - val_loss: 0.0962 - val_accuracy: 0.9701\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0779 - accuracy: 0.9770 - val_loss: 0.0872 - val_accuracy: 0.9736\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0608 - accuracy: 0.9812 - val_loss: 0.0787 - val_accuracy: 0.9770\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0452 - accuracy: 0.9861 - val_loss: 0.0716 - val_accuracy: 0.9799\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0364 - accuracy: 0.9891 - val_loss: 0.0738 - val_accuracy: 0.9770\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.0830 - val_accuracy: 0.9751\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0229 - accuracy: 0.9931 - val_loss: 0.0762 - val_accuracy: 0.9779\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0191 - accuracy: 0.9942 - val_loss: 0.0776 - val_accuracy: 0.9791\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 4s 2ms/step - loss: 0.0169 - accuracy: 0.9949 - val_loss: 0.0752 - val_accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x14ad145f8>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logdir = os.path.join(\"logs/additional_layers\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(logdir, histogram_freq=1)\n",
    "\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28,28)),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(10, activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(x=X_train, \n",
    "        y=y_train, \n",
    "        epochs=10, \n",
    "        validation_data=(X_test, y_test), \n",
    "        callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zv_3xNMjzdLI"
   },
   "source": [
    "## Stretch Goals:\n",
    "\n",
    "- Use Hyperparameter Tuning to make the accuracy of your models as high as possible. (error as low as possible)\n",
    "- Use Cross Validation techniques to get more consistent results with your model.\n",
    "- Use GridSearchCV to try different combinations of hyperparameters. \n",
    "- Start looking into other types of Keras layers for CNNs and RNNs maybe try and build a CNN model for fashion-MNIST to see how the results compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "LS_DS_433_Keras_Assignment.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "U4-S2-NNF (Python3)",
   "language": "python",
   "name": "u4-s2-nnf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
